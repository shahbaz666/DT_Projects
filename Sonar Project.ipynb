{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sonar.all-data.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'M'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x5c3bb5d608>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANjElEQVR4nO3df6zd9V3H8edrdASYEsp6wdKCBdNMCW6AN4hbYpZVk7HNtVmAQJxrGEn9Axlz/qDuDzEzJiyisy7LkoYfK8vCIN20bJkzpILGqNXbgeNHJTSopaPQy/g1dTqLb/843368lFs4tvec723P85HcnPP9nu85501S+uz3+z3fc1NVSJIE8Ka+B5AkLR5GQZLUGAVJUmMUJEmNUZAkNUv6HuBoLFu2rFatWtX3GJJ0TNm5c+dzVTU132PHdBRWrVrFzMxM32NI0jElyb8e7jEPH0mSGqMgSWqMgiSpMQqSpMYoSJIaoyBJaoyCJKkxCpKkxihIkppj+opm6Xi251M/2fcIWoTO+e2HR/r67ilIkhqjIElqjIIkqTEKkqTGKEiSGqMgSWqMgiSpMQqSpMYoSJIaoyBJaoyCJKkxCpKkxihIkhqjIElqjIIkqTEKkqRmZFFIcnuS/UkembPu9CT3JXmiu13arU+SP06yO8m3k1w8qrkkSYc3yj2FLwDvPWTdRmB7Va0GtnfLAJcBq7ufDcDnRziXJOkwRhaFqvor4PlDVq8FtnT3twDr5qy/swb+DjgtyfJRzSZJmt+4zymcWVX7ALrbM7r1K4Cn5my3t1v3Gkk2JJlJMjM7OzvSYSVp0iyWE82ZZ13Nt2FVba6q6aqanpqaGvFYkjRZxh2FZw8eFupu93fr9wJnz9luJfD0mGeTpIk37ijcC6zv7q8Hts1Z/5HuU0iXAi8dPMwkSRqfJaN64SR3Ae8GliXZC9wE3Azck+RaYA9wRbf5N4D3AbuB/wCuGdVckqTDG1kUqurqwzy0Zp5tC7huVLNIkoYzsigcK37qN+7sewQtQjt//yN9jyD1YrF8+kiStAgYBUlSYxQkSY1RkCQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktQYBUlSYxQkSY1RkCQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktQYBUlSYxQkSU0vUUjyq0keTfJIkruSnJTk3CQ7kjyR5O4kJ/YxmyRNsrFHIckK4GPAdFVdAJwAXAV8GvhMVa0GXgCuHfdskjTp+jp8tAQ4OckS4BRgH/AeYGv3+BZgXU+zSdLEGnsUquo7wC3AHgYxeAnYCbxYVQe6zfYCK8Y9myRNuj4OHy0F1gLnAmcBbwEum2fTOszzNySZSTIzOzs7ukElaQL1cfjo54B/rqrZqvpv4KvAO4HTusNJACuBp+d7clVtrqrpqpqempoaz8SSNCH6iMIe4NIkpyQJsAZ4DLgfuLzbZj2wrYfZJGmi9XFOYQeDE8rfAh7uZtgM3Ah8Islu4K3AbeOeTZIm3ZI33mThVdVNwE2HrH4SuKSHcSRJHa9oliQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktQYBUlSYxQkSY1RkCQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktQYBUlSYxQkSc1QUUiyfZh1kqRj25LXezDJScApwLIkS4F0D50KnDXi2SRJY/a6UQB+Gfg4gwDs5P+i8DLwuRHOJUnqwetGoao2AZuSXF9Vnx3TTJKknrzRngIAVfXZJO8EVs19TlXdOaK5JEk9GCoKSb4I/BjwEPBKt7qAI4pCktOAW4ELutf5KPA4cDeD8PwLcGVVvXAkry9JOjJDRQGYBs6vqlqg990EfLOqLk9yIoOT2Z8EtlfVzUk2AhuBGxfo/SRJQxj2OoVHgB9ZiDdMcirws8BtAFX1g6p6EVgLbOk22wKsW4j3kyQNb9g9hWXAY0n+Hvivgyur6oNH8J7nAbPAHUneweBTTTcAZ1bVvu519yU5Y74nJ9kAbAA455xzjuDtJUmHM2wUfmeB3/Ni4Pqq2pFkE4NDRUOpqs3AZoDp6emFOpwlSWL4Tx/95QK+515gb1Xt6Ja3MojCs0mWd3sJy4H9C/iekqQhDPs1F99L8nL3859JXkny8pG8YVU9AzyV5G3dqjXAY8C9wPpu3Xpg25G8viTpyA27p/DDc5eTrAMuOYr3vR74UvfJoyeBaxgE6p4k1wJ7gCuO4vUlSUdg2HMKr1JVf9p9bPSIVNVDDD7meqg1R/qakqSjN+zFax+as/gmBn+he5JXko4zw+4p/MKc+wcYXHG8dsGnkST1athzCteMehBJUv+G/fTRyiR/kmR/kmeTfCXJylEPJ0kar2G/5uIOBh8ZPQtYAXytWydJOo4MG4Wpqrqjqg50P18ApkY4lySpB8NG4bkkH05yQvfzYeC7oxxMkjR+w0bho8CVwDPAPuByBhecSZKOI8N+JPV3gfUHf+lNktOBWxjEQpJ0nBh2T+Htc38LWlU9D1w0mpEkSX0ZNgpvSrL04EK3p3BEX5EhSVq8hv2L/Q+Av0mylcHXW1wJ/N7IppIk9WLYK5rvTDIDvAcI8KGqemykk0mSxm7oQ0BdBAyBJB3Hhj2nIEmaAEZBktQYBUlSYxQkSY1RkCQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktT0FoUkJyR5MMnXu+Vzk+xI8kSSu5Oc2NdskjSp+txTuAHYNWf508Bnqmo18AJwbS9TSdIE6yUKSVYC7wdu7ZbD4Le6be022QKs62M2SZpkfe0p/BHwm8D/dMtvBV6sqgPd8l5gxXxPTLIhyUySmdnZ2dFPKkkTZOxRSPIBYH9V7Zy7ep5Na77nV9XmqpququmpqamRzChJk2ro39G8gN4FfDDJ+4CTgFMZ7DmclmRJt7ewEni6h9kkaaKNfU+hqn6rqlZW1SrgKuAvquoXgfuBy7vN1gPbxj2bJE26xXSdwo3AJ5LsZnCO4bae55GkidPH4aOmqh4AHujuPwlc0uc8kjTpFtOegiSpZ0ZBktQYBUlSYxQkSY1RkCQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktQYBUlSYxQkSY1RkCQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktQYBUlSYxQkSc3Yo5Dk7CT3J9mV5NEkN3TrT09yX5Inutul455NkiZdH3sKB4Bfq6qfAC4FrktyPrAR2F5Vq4Ht3bIkaYzGHoWq2ldV3+rufw/YBawA1gJbus22AOvGPZskTbpezykkWQVcBOwAzqyqfTAIB3DGYZ6zIclMkpnZ2dlxjSpJE6G3KCT5IeArwMer6uVhn1dVm6tquqqmp6amRjegJE2gXqKQ5M0MgvClqvpqt/rZJMu7x5cD+/uYTZImWR+fPgpwG7Crqv5wzkP3Auu7++uBbeOeTZIm3ZIe3vNdwC8BDyd5qFv3SeBm4J4k1wJ7gCt6mE2SJtrYo1BVfw3kMA+vGecskqRX84pmSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktQYBUlSYxQkSY1RkCQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUmMUJEmNUZAkNUZBktQYBUlSYxQkSY1RkCQ1RkGS1BgFSVJjFCRJjVGQJDVGQZLUGAVJUrOoopDkvUkeT7I7yca+55GkSbNoopDkBOBzwGXA+cDVSc7vdypJmiyLJgrAJcDuqnqyqn4AfBlY2/NMkjRRlvQ9wBwrgKfmLO8FfvrQjZJsADZ0i/+W5PExzDYplgHP9T3EYpBb1vc9gl7NP5sH3ZSFeJUfPdwDiykK8/2X1mtWVG0GNo9+nMmTZKaqpvueQzqUfzbHZzEdPtoLnD1neSXwdE+zSNJEWkxR+AdgdZJzk5wIXAXc2/NMkjRRFs3ho6o6kORXgD8HTgBur6pHex5r0nhYTouVfzbHJFWvOWwvSZpQi+nwkSSpZ0ZBktQYhQmX5JUkDyV5JMnXkpzW90wSQJJK8sU5y0uSzCb5ep9zHe+Mgr5fVRdW1QXA88B1fQ8kdf4duCDJyd3yzwPf6XGeiWAUNNffMriyXFos/gx4f3f/auCuHmeZCEZBQPtCwjV4bYgWly8DVyU5CXg7sKPneY57RkEnJ3kI+C5wOnBfz/NITVV9G1jFYC/hG/1OMxmMgr5fVRcy+IKsE/Gcghafe4Fb8NDRWBgFAVBVLwEfA349yZv7nkea43bgU1X1cN+DTAKjoKaqHgT+kcH3TkmLQlXtrapNfc8xKfyaC0lS456CJKkxCpKkxihIkhqjIElqjIIkqTEK0gJIclqSrUn+KcmuJD+T5PQk9yV5ortd2vec0hsxCtLC2AR8s6p+HHgHsAvYCGyvqtXA9m5ZWtS8TkE6SklOZXDR33k153+oJI8D766qfUmWAw9U1dv6mlMahnsK0tE7D5gF7kjyYJJbk7wFOLOq9gF0t2f0OaQ0DKMgHb0lwMXA56vqIga/HMZDRTomGQXp6O0F9lbVwe/638ogEs92h43obvf3NJ80NKMgHaWqegZ4KsnB8wVrgMcYfOXz+m7demBbD+NJ/y+eaJYWQJILgVsZ/E6KJ4FrGPyj6x7gHGAPcEVVPd/bkNIQjIIkqfHwkSSpMQqSpMYoSJIaoyBJaoyCJKkxCpKkxihIkpr/BbaI7HILz7qZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=60, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x5c3c3dac88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2.131088\n",
       "1     2.155644\n",
       "2     2.652518\n",
       "3     3.401697\n",
       "4     2.018141\n",
       "5     1.248166\n",
       "6     0.970820\n",
       "7     1.481107\n",
       "8     1.633870\n",
       "9     1.281258\n",
       "10    0.987813\n",
       "11    0.588681\n",
       "12    0.736584\n",
       "13    1.022369\n",
       "14    0.763964\n",
       "15    0.694671\n",
       "16    0.654480\n",
       "17    0.525845\n",
       "18    0.283182\n",
       "19   -0.085331\n",
       "20   -0.252741\n",
       "21   -0.392289\n",
       "22   -0.594350\n",
       "23   -0.691861\n",
       "24   -0.788909\n",
       "25   -0.671580\n",
       "26   -0.627843\n",
       "27   -0.615447\n",
       "28   -0.442007\n",
       "29   -0.132390\n",
       "30    0.259797\n",
       "31    0.313420\n",
       "32    0.423864\n",
       "33    0.563296\n",
       "34    0.591654\n",
       "35    0.619868\n",
       "36    0.676994\n",
       "37    1.033366\n",
       "38    0.908835\n",
       "39    0.861280\n",
       "40    0.863526\n",
       "41    0.860110\n",
       "42    0.909317\n",
       "43    1.235086\n",
       "44    1.366839\n",
       "45    1.706674\n",
       "46    1.790155\n",
       "47    1.277722\n",
       "48    1.273385\n",
       "49    1.761714\n",
       "50    2.716060\n",
       "51    2.093976\n",
       "52    1.060572\n",
       "53    1.093090\n",
       "54    1.789946\n",
       "55    1.780805\n",
       "56    1.653090\n",
       "57    2.098330\n",
       "58    1.737506\n",
       "59    2.775754\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   1  \n",
       "1  0.0052  0.0044   1  \n",
       "2  0.0095  0.0078   1  \n",
       "3  0.0040  0.0117   1  \n",
       "4  0.0107  0.0094   1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[60] = le.fit_transform(df[60])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39955135, 0.04064823, 0.02692565, ..., 0.17167808, 0.65894689,\n",
       "        1.06973356],\n",
       "       [0.70353822, 0.42163039, 1.05561832, ..., 0.44455424, 0.41985233,\n",
       "        1.06973356],\n",
       "       [0.12922901, 0.60106749, 1.72340448, ..., 0.25276128, 0.25758223,\n",
       "        1.06973356],\n",
       "       ...,\n",
       "       [1.00438083, 0.16007801, 0.67384349, ..., 0.03913824, 0.67887143,\n",
       "        0.93481221],\n",
       "       [0.04953255, 0.09539176, 0.13480381, ..., 0.70402047, 0.34015415,\n",
       "        0.93481221],\n",
       "       [0.13794908, 0.06497869, 0.78861924, ..., 0.29860448, 0.99479044,\n",
       "        0.93481221]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "z = np.abs(zscore(df))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 61)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df[(z<3).all(axis=1)]\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.260141\n",
       "1     1.305137\n",
       "2     1.651471\n",
       "3     1.237233\n",
       "4     0.921870\n",
       "        ...   \n",
       "56    1.378156\n",
       "57    1.364882\n",
       "58    1.464334\n",
       "59    1.144572\n",
       "60    0.000000\n",
       "Length: 61, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.drop(60, axis = 1)\n",
    "y = df_new[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy score corresponding to random state 144 is 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "max_accuracy_score=0\n",
    "for r_state in range(42,250):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25,random_state=r_state)\n",
    "    logr = LogisticRegression()\n",
    "    logr.fit(X_train,y_train)\n",
    "    y_pred = logr.predict(X_test)\n",
    "    accu_scr = accuracy_score(y_test,y_pred)\n",
    "    if accu_scr>max_accuracy_score:\n",
    "        max_accuracy_score = accu_scr\n",
    "        final_r_state = r_state\n",
    "    \n",
    "print(\"max accuracy score corresponding to random state\",final_r_state,\"is\",max_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25,random_state=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.9285714285714286\n",
      "Confusion Matrix \n",
      "[[23  1]\n",
      " [ 2 16]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        24\n",
      "           1       0.94      0.89      0.91        18\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.93      0.92      0.93        42\n",
      "weighted avg       0.93      0.93      0.93        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "predlr = lr.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predlr)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predlr)))\n",
    "print(\"Classification Report\\n{}\".format(classification_report(y_test,predlr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "neighbors = {\"n_neighbors\":range(1,10)}\n",
    "knc = KNeighborsClassifier()\n",
    "gknr = GridSearchCV(knc,neighbors,cv=10)\n",
    "gknr.fit(X,y)\n",
    "gknr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.8571428571428571\n",
      "Confusion Matrix \n",
      "[[21  3]\n",
      " [ 3 15]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        24\n",
      "           1       0.83      0.83      0.83        18\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.85      0.85      0.85        42\n",
      "weighted avg       0.86      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)\n",
    "predknn = knn.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predknn)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predknn)))\n",
    "print(\"Classification Report\\n{}\".format(classification_report(y_test,predknn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52941176, 0.82352941, 0.5       , 0.93939394, 0.48484848])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "a_score = cross_val_score(LogisticRegression(),X,y,cv=5,scoring=\"accuracy\")\n",
    "a_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.8571428571428571\n",
      "Confusion Matrix \n",
      "[[20  4]\n",
      " [ 2 16]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        24\n",
      "           1       0.80      0.89      0.84        18\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.85      0.86      0.86        42\n",
      "weighted avg       0.86      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = GaussianNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "predmnb = mnb.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predmnb)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predmnb)))\n",
    "print(\"Classification Report\\n{}\".format(classification_report(y_test,predmnb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.7619047619047619\n",
      "Confusion Matrix \n",
      "[[17  7]\n",
      " [ 3 15]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77        24\n",
      "           1       0.68      0.83      0.75        18\n",
      "\n",
      "    accuracy                           0.76        42\n",
      "   macro avg       0.77      0.77      0.76        42\n",
      "weighted avg       0.78      0.76      0.76        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "predmnb = mnb.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predmnb)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predmnb)))\n",
    "print(\"Classification Report\\n{}\".format(classification_report(y_test,predmnb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.8809523809523809\n",
      "Confusion Matrix \n",
      "[[20  4]\n",
      " [ 1 17]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89        24\n",
      "           1       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.88      0.89      0.88        42\n",
      "weighted avg       0.89      0.88      0.88        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train,y_train)\n",
    "predsvc = svc.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predsvc)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predsvc)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predsvc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.8809523809523809\n",
      "Confusion Matrix \n",
      "[[23  1]\n",
      " [ 4 14]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        24\n",
      "           1       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.89      0.87      0.88        42\n",
      "weighted avg       0.89      0.88      0.88        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train,y_train)\n",
    "predsvc = svc.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predsvc)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predsvc)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predsvc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.9523809523809523\n",
      "Confusion Matrix \n",
      "[[24  0]\n",
      " [ 2 16]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        24\n",
      "           1       1.00      0.89      0.94        18\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.96      0.94      0.95        42\n",
      "weighted avg       0.96      0.95      0.95        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='poly')\n",
    "svc.fit(X_train,y_train)\n",
    "predsvc = svc.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predsvc)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predsvc)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predsvc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.7142857142857143\n",
      "Confusion Matrix \n",
      "[[17  7]\n",
      " [ 5 13]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        24\n",
      "           1       0.65      0.72      0.68        18\n",
      "\n",
      "    accuracy                           0.71        42\n",
      "   macro avg       0.71      0.72      0.71        42\n",
      "weighted avg       0.72      0.71      0.72        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "#default:criterion='gini'\n",
    "dtc.fit(X_train,y_train)\n",
    "preddtc = dtc.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,preddtc)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,preddtc)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,preddtc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.9523809523809523\n",
      "Confusion Matrix \n",
      "[[23  1]\n",
      " [ 1 17]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        24\n",
      "           1       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.95      0.95      0.95        42\n",
      "weighted avg       0.95      0.95      0.95        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 250, random_state = 144)\n",
    "rf.fit(X_train,y_train)\n",
    "predrf = rf.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predrf)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predrf)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predrf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.8571428571428571\n",
      "Confusion Matrix \n",
      "[[20  4]\n",
      " [ 2 16]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        24\n",
      "           1       0.80      0.89      0.84        18\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.85      0.86      0.86        42\n",
      "weighted avg       0.86      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ad = AdaBoostClassifier()\n",
    "#AdaBoostClassifier(base_estimators=DecisionTreeClassifier(),n_estimators=50,learning_rate=1.0)\n",
    "ad.fit(X_train,y_train)\n",
    "predad = ad.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predad)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predad)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.9047619047619048\n",
      "Confusion Matrix \n",
      "[[22  2]\n",
      " [ 2 16]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        24\n",
      "           1       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.90      0.90      0.90        42\n",
      "weighted avg       0.90      0.90      0.90        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ad1 = AdaBoostClassifier(n_estimators=250)\n",
    "ad1.fit(X_train,y_train)\n",
    "predad1 = ad1.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predad1)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predad1)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predad1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.42857142857142855\n",
      "Confusion Matrix \n",
      "[[ 0 24]\n",
      " [ 0 18]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.43      1.00      0.60        18\n",
      "\n",
      "    accuracy                           0.43        42\n",
      "   macro avg       0.21      0.50      0.30        42\n",
      "weighted avg       0.18      0.43      0.26        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "ad = AdaBoostClassifier(n_estimators=50,base_estimator=svc,algorithm='SAMME')\n",
    "ad.fit(X_train,y_train)\n",
    "predad = ad.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predad)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predad)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.9523809523809523\n",
      "Confusion Matrix \n",
      "[[23  1]\n",
      " [ 1 17]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        24\n",
      "           1       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.95      0.95      0.95        42\n",
      "weighted avg       0.95      0.95      0.95        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(probability=True,kernel='poly')\n",
    "ad = AdaBoostClassifier(n_estimators=45,base_estimator=svc)\n",
    "ad.fit(X_train,y_train)\n",
    "predad = ad.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predad)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predad)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'n_estimators': 100}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "parameters = {\"learning_rate\":[0.001,0.01,0.1,1,10],\"n_estimators\":[10,100,250,400]}\n",
    "clf=GridSearchCV(gbc, parameters, cv=5)\n",
    "clf.fit(X,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.8571428571428571\n",
      "Confusion Matrix \n",
      "[[20  4]\n",
      " [ 2 16]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        24\n",
      "           1       0.80      0.89      0.84        18\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.85      0.86      0.86        42\n",
      "weighted avg       0.86      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(learning_rate = 1,n_estimators = 100,random_state=144)\n",
    "gb.fit(X_train,y_train)\n",
    "predgb = gb.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predgb)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predgb)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.8333333333333334\n",
      "Confusion Matrix \n",
      "[[20  4]\n",
      " [ 3 15]]\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85        24\n",
      "           1       0.79      0.83      0.81        18\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.83      0.83      0.83        42\n",
      "weighted avg       0.84      0.83      0.83        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xg = xgb.XGBClassifier(random_state=235)\n",
    "xg.fit(X_train, y_train)\n",
    "predxg = xg.predict(X_test)\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,predxg)))\n",
    "print(\"Confusion Matrix \\n{}\".format(confusion_matrix(y_test,predxg)))\n",
    "print(\"Classification Report{}\".format(classification_report(y_test,predxg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "x_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.53875493  0.55086154 -0.31581947 ...  0.09845361  0.44297842\n",
      "  -0.39037274]\n",
      " [-1.0946115   0.92225087  0.77914686 ...  0.36738531 -0.14232998\n",
      "  -0.33252725]\n",
      " [-0.06061299  0.29442318  0.59096689 ...  0.28864927  0.16130533\n",
      "   0.08732235]\n",
      " ...\n",
      " [ 0.56369938 -0.90865883  0.21152548 ...  0.11308594 -0.25007869\n",
      "  -0.02277359]\n",
      " [ 0.17998902 -0.87639692  0.20283177 ... -0.01695201 -0.06608524\n",
      "  -0.01033911]\n",
      " [ 0.15602373 -0.77595947  0.01294476 ...  0.01875515 -0.06482331\n",
      "   0.10670562]]\n"
     ]
    }
   ],
   "source": [
    "pca_new = PCA(n_components=8)\n",
    "x_new = pca_new.fit_transform(X)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sonar_clf.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf,'sonar_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
